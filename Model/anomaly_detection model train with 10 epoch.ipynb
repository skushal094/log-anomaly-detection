{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "anomaly_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7lKzXZ-yUl"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGeNhGm5o7jh"
      },
      "source": [
        "random.seed(0)\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uMjtpRDr-Da"
      },
      "source": [
        "# Change this to run locally\n",
        "is_local = True\n",
        "if is_local:\n",
        "  data_loc = \"/content/drive/MyDrive/SE Research Project/project_processed_data/\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  data_loc = \"./drive/MyDrive/log_data/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsxvHdJI-yUt"
      },
      "source": [
        "## Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoav9WT1-yUu"
      },
      "source": [
        "# Train sets\n",
        "train_data = np.load('{}x_train_tf-idf_v5.npy'.format(data_loc))\n",
        "read_train_labels = pd.read_csv('{}y_train_tf-idf_v5.csv'.format(data_loc))\n",
        "train_labels = read_train_labels['Label'] == 'Anomaly'\n",
        "train_labels = train_labels.astype(int)\n",
        "\n",
        "# Test sets\n",
        "test_data = np.load('{}x_test_tf-idf_v5.npy'.format(data_loc))\n",
        "read_test_labels = pd.read_csv('{}y_test_tf-idf_v5.csv'.format(data_loc))\n",
        "test_labels = read_test_labels['Label'] == 'Anomaly'\n",
        "test_labels = test_labels.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X09WrmMF-yUu"
      },
      "source": [
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta7khuA6F3e7",
        "outputId": "61c8be36-d3cb-47d0-a878-6e5ad31f1980"
      },
      "source": [
        "train_labels = train_labels.reset_index(drop=True)\n",
        "val_labels = val_labels.reset_index(drop=True)\n",
        "\n",
        "print(\"train data shape\")\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(\"val data shape\")\n",
        "print(val_data.shape)\n",
        "print(val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data shape\n",
            "(315602, 16, 46)\n",
            "(315602,)\n",
            "val data shape\n",
            "(78901, 16, 46)\n",
            "(78901,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNcDmplg4GOp",
        "outputId": "ba963274-36b9-405d-9944-921f8454be85"
      },
      "source": [
        "print(len(test_labels))\n",
        "anom = test_labels[test_labels > 0]\n",
        "norm = test_labels[test_labels == 0]\n",
        "print(anom.shape)\n",
        "print(norm.shape)\n",
        "\n",
        "print(len(anom)/len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120537\n",
            "(1983,)\n",
            "(118554,)\n",
            "0.016451380074168097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL1F69-SsShW",
        "outputId": "f866b8df-71e5-4273-e89b-b418dbb15240"
      },
      "source": [
        "print(len(train_labels))\n",
        "anom = train_labels[train_labels > 0]\n",
        "norm = train_labels[train_labels == 0]\n",
        "print(anom.shape)\n",
        "print(norm.shape)\n",
        "\n",
        "print(len(anom)/len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315602\n",
            "(9825,)\n",
            "(305777,)\n",
            "0.03113098142597322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPraFUqn-yUx"
      },
      "source": [
        "class logDataset(Dataset):\n",
        "    \"\"\"Log Anomaly Features Dataset\"\"\"\n",
        "    \n",
        "    def __init__(self, data_vec, labels=None):\n",
        "        self.X = data_vec\n",
        "        self.y = labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        data_matrix = self.X[idx]\n",
        "        \n",
        "        if not self.y is None:\n",
        "            return(data_matrix, self.y[idx])\n",
        "        else:\n",
        "            return data_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol2-sxy5-yUy"
      },
      "source": [
        "# add 1 1 1 1 for padding\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "train_data = F.pad(input=train_data, pad=(1, 1, 1, 1), mode='constant', value=0) # pad all sides with 0s\n",
        "train_data = np.expand_dims(train_data, axis=1)\n",
        "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "test_data = F.pad(input=test_data, pad=(1, 1, 1, 1), mode='constant', value=0)\n",
        "test_data = np.expand_dims(test_data, axis=1)\n",
        "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
        "val_data = F.pad(input=val_data, pad=(1, 1, 1, 1), mode='constant', value=0)\n",
        "val_data = np.expand_dims(val_data, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShW0RdNY-yU0"
      },
      "source": [
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Other\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda:0\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrWfRD0uWfgG",
        "outputId": "b5d75ecb-692f-42c6-8286-478eefeb32ff"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7_3tMRl-yU0"
      },
      "source": [
        "# pass datasets into the custom dataclass\n",
        "train_dataset = logDataset(train_data, labels = train_labels)\n",
        "test_dataset = logDataset(test_data, labels = test_labels)\n",
        "val_dataset = logDataset(val_data, labels = val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWwa2PG_-yU1",
        "outputId": "0d4528e5-9d2a-4fbf-9eb3-9202782d0843"
      },
      "source": [
        "# use DataLoader class\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          num_workers=0, # couldn't use workers https://github.com/fastai/fastbook/issues/85\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=0,\n",
        "                         shuffle=False)\n",
        "\n",
        "val_loader = DataLoader(dataset=val_dataset, \n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=0,\n",
        "                         shuffle=False)\n",
        "\n",
        "\n",
        "# Checking the dataset\n",
        "for data, labels in train_loader:  \n",
        "    print('Matrix batch dimensions:', data.shape)\n",
        "    print('Matrix label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "# Checking the dataset\n",
        "for data, labels in test_loader:  \n",
        "    print('Matrix batch dimensions:', data.shape)\n",
        "    print('Matrix label dimensions:', labels.shape)\n",
        "    break\n",
        "    \n",
        "# Checking the dataset\n",
        "for data, labels in val_loader:  \n",
        "    print('Matrix batch dimensions:', data.shape)\n",
        "    print('Matrix label dimensions:', labels.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix batch dimensions: torch.Size([128, 1, 18, 48])\n",
            "Matrix label dimensions: torch.Size([128])\n",
            "Matrix batch dimensions: torch.Size([128, 1, 18, 48])\n",
            "Matrix label dimensions: torch.Size([128])\n",
            "Matrix batch dimensions: torch.Size([128, 1, 18, 48])\n",
            "Matrix label dimensions: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbvFNaRk-yU2"
      },
      "source": [
        "## Setup Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFxoCAHg-yU2",
        "outputId": "4c731ab4-8ad8-4cb4-8acb-3a1942568c8e"
      },
      "source": [
        "# Check that the train loader works correctly\n",
        "device = torch.device(DEVICE)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "for epoch in range(2):\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        \n",
        "        print('Epoch:', epoch+1, end='')\n",
        "        print(' | Batch index:', batch_idx, end='')\n",
        "        print(' | Batch size:', y.size()[0])\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
            "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doCsnPrG-yU2"
      },
      "source": [
        "##########################\n",
        "### MODEL\n",
        "##########################\n",
        "\n",
        "\n",
        "class logCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(logCNN, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 16, kernel_size=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "\n",
        "            nn.Linear(1056, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, num_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZLIAStI-yU3"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = logCNN(NUM_CLASSES)\n",
        "model.to(DEVICE)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr-b4WVw-yU3"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeNobFr9-yU4",
        "outputId": "adb92bba-8ff0-4a95-d7b5-ea2d6f3b5ad8"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "            \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE, dtype=torch.long) # had to pass in to torch.long based on the 1, 0 int labels\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "# This needs to be vectorized\n",
        "def compute_f1(model, data_loader, device):\n",
        "    y_hats = []\n",
        "    y_acts = []\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        yhat = model(inputs)[-1].cpu().detach().numpy().round()\n",
        "        # yhat = model(inputs)[-1].to(DEVICE).detach().numpy().round()\n",
        "        yhat = np.argmax(yhat, axis=1)\n",
        "        y_hats.append(yhat)\n",
        "        y_acts.append(list(targets.cpu().detach().numpy()))\n",
        "    \n",
        "    y_hats = [item for sublist in y_hats for item in sublist]\n",
        "    y_acts = [item for sublist in y_acts for item in sublist]\n",
        "    return f1_score(y_acts, y_hats)\n",
        "\n",
        "  \n",
        "\n",
        "start_time = time.time()\n",
        "minibatch_cost = []\n",
        "epoch_train_performance = []\n",
        "epoch_val_performance = []\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE, dtype=torch.long) # another had to use torch.long\n",
        "            \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        \n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        minibatch_cost.append(cost)\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
        "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
        "                     len(train_loader), cost, ))\n",
        "\n",
        "        \n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        train_performance = compute_f1(model, train_loader, device=DEVICE)\n",
        "        val_performance = compute_f1(model, val_loader, device=DEVICE)\n",
        "        epoch_train_performance.append(train_performance)\n",
        "        epoch_val_performance.append(val_performance)\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%%   | Val: %.3f%%' % (\n",
        "              epoch+1, NUM_EPOCHS, train_performance, val_performance))\n",
        "        \n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "    \n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/010 | Batch 0000/2466 | Cost: 0.7391\n",
            "Epoch: 001/010 | Batch 0050/2466 | Cost: 0.0245\n",
            "Epoch: 001/010 | Batch 0100/2466 | Cost: 0.0055\n",
            "Epoch: 001/010 | Batch 0150/2466 | Cost: 0.0801\n",
            "Epoch: 001/010 | Batch 0200/2466 | Cost: 0.0011\n",
            "Epoch: 001/010 | Batch 0250/2466 | Cost: 0.0002\n",
            "Epoch: 001/010 | Batch 0300/2466 | Cost: 0.0042\n",
            "Epoch: 001/010 | Batch 0350/2466 | Cost: 0.0002\n",
            "Epoch: 001/010 | Batch 0400/2466 | Cost: 0.0022\n",
            "Epoch: 001/010 | Batch 0450/2466 | Cost: 0.0059\n",
            "Epoch: 001/010 | Batch 0500/2466 | Cost: 0.0003\n",
            "Epoch: 001/010 | Batch 0550/2466 | Cost: 0.0003\n",
            "Epoch: 001/010 | Batch 0600/2466 | Cost: 0.0005\n",
            "Epoch: 001/010 | Batch 0650/2466 | Cost: 0.0001\n",
            "Epoch: 001/010 | Batch 0700/2466 | Cost: 0.0012\n",
            "Epoch: 001/010 | Batch 0750/2466 | Cost: 0.0003\n",
            "Epoch: 001/010 | Batch 0800/2466 | Cost: 0.0244\n",
            "Epoch: 001/010 | Batch 0850/2466 | Cost: 0.0022\n",
            "Epoch: 001/010 | Batch 0900/2466 | Cost: 0.0008\n",
            "Epoch: 001/010 | Batch 0950/2466 | Cost: 0.0024\n",
            "Epoch: 001/010 | Batch 1000/2466 | Cost: 0.0007\n",
            "Epoch: 001/010 | Batch 1050/2466 | Cost: 0.0033\n",
            "Epoch: 001/010 | Batch 1100/2466 | Cost: 0.0001\n",
            "Epoch: 001/010 | Batch 1150/2466 | Cost: 0.0045\n",
            "Epoch: 001/010 | Batch 1200/2466 | Cost: 0.0011\n",
            "Epoch: 001/010 | Batch 1250/2466 | Cost: 0.0009\n",
            "Epoch: 001/010 | Batch 1300/2466 | Cost: 0.0000\n",
            "Epoch: 001/010 | Batch 1350/2466 | Cost: 0.0020\n",
            "Epoch: 001/010 | Batch 1400/2466 | Cost: 0.0004\n",
            "Epoch: 001/010 | Batch 1450/2466 | Cost: 0.0110\n",
            "Epoch: 001/010 | Batch 1500/2466 | Cost: 0.0006\n",
            "Epoch: 001/010 | Batch 1550/2466 | Cost: 0.0012\n",
            "Epoch: 001/010 | Batch 1600/2466 | Cost: 0.0000\n",
            "Epoch: 001/010 | Batch 1650/2466 | Cost: 0.0001\n",
            "Epoch: 001/010 | Batch 1700/2466 | Cost: 0.0563\n",
            "Epoch: 001/010 | Batch 1750/2466 | Cost: 0.0012\n",
            "Epoch: 001/010 | Batch 1800/2466 | Cost: 0.0002\n",
            "Epoch: 001/010 | Batch 1850/2466 | Cost: 0.0003\n",
            "Epoch: 001/010 | Batch 1900/2466 | Cost: 0.0002\n",
            "Epoch: 001/010 | Batch 1950/2466 | Cost: 0.0004\n",
            "Epoch: 001/010 | Batch 2000/2466 | Cost: 0.0018\n",
            "Epoch: 001/010 | Batch 2050/2466 | Cost: 0.0000\n",
            "Epoch: 001/010 | Batch 2100/2466 | Cost: 0.0001\n",
            "Epoch: 001/010 | Batch 2150/2466 | Cost: 0.0001\n",
            "Epoch: 001/010 | Batch 2200/2466 | Cost: 0.0001\n",
            "Epoch: 001/010 | Batch 2250/2466 | Cost: 0.0007\n",
            "Epoch: 001/010 | Batch 2300/2466 | Cost: 0.0012\n",
            "Epoch: 001/010 | Batch 2350/2466 | Cost: 0.0004\n",
            "Epoch: 001/010 | Batch 2400/2466 | Cost: 0.0040\n",
            "Epoch: 001/010 | Batch 2450/2466 | Cost: 0.0002\n",
            "Epoch: 001/010 | Train: 0.990%   | Val: 0.991%\n",
            "Time elapsed: 2.85 min\n",
            "Epoch: 002/010 | Batch 0000/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 0050/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 0100/2466 | Cost: 0.0003\n",
            "Epoch: 002/010 | Batch 0150/2466 | Cost: 0.0003\n",
            "Epoch: 002/010 | Batch 0200/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 0250/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 0300/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 0350/2466 | Cost: 0.0009\n",
            "Epoch: 002/010 | Batch 0400/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 0450/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 0500/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 0550/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 0600/2466 | Cost: 0.0006\n",
            "Epoch: 002/010 | Batch 0650/2466 | Cost: 0.0021\n",
            "Epoch: 002/010 | Batch 0700/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 0750/2466 | Cost: 0.0004\n",
            "Epoch: 002/010 | Batch 0800/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 0850/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 0900/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 0950/2466 | Cost: 0.0004\n",
            "Epoch: 002/010 | Batch 1000/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 1050/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 1100/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 1150/2466 | Cost: 0.0003\n",
            "Epoch: 002/010 | Batch 1200/2466 | Cost: 0.0600\n",
            "Epoch: 002/010 | Batch 1250/2466 | Cost: 0.0024\n",
            "Epoch: 002/010 | Batch 1300/2466 | Cost: 0.0003\n",
            "Epoch: 002/010 | Batch 1350/2466 | Cost: 0.0298\n",
            "Epoch: 002/010 | Batch 1400/2466 | Cost: 0.0006\n",
            "Epoch: 002/010 | Batch 1450/2466 | Cost: 0.0013\n",
            "Epoch: 002/010 | Batch 1500/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 1550/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 1600/2466 | Cost: 0.0003\n",
            "Epoch: 002/010 | Batch 1650/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 1700/2466 | Cost: 0.0004\n",
            "Epoch: 002/010 | Batch 1750/2466 | Cost: 0.0023\n",
            "Epoch: 002/010 | Batch 1800/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 1850/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 1900/2466 | Cost: 0.0004\n",
            "Epoch: 002/010 | Batch 1950/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 2000/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 2050/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 2100/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Batch 2150/2466 | Cost: 0.0042\n",
            "Epoch: 002/010 | Batch 2200/2466 | Cost: 0.0004\n",
            "Epoch: 002/010 | Batch 2250/2466 | Cost: 0.0006\n",
            "Epoch: 002/010 | Batch 2300/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 2350/2466 | Cost: 0.0001\n",
            "Epoch: 002/010 | Batch 2400/2466 | Cost: 0.0000\n",
            "Epoch: 002/010 | Batch 2450/2466 | Cost: 0.0002\n",
            "Epoch: 002/010 | Train: 0.993%   | Val: 0.993%\n",
            "Time elapsed: 5.77 min\n",
            "Epoch: 003/010 | Batch 0000/2466 | Cost: 0.0004\n",
            "Epoch: 003/010 | Batch 0050/2466 | Cost: 0.0009\n",
            "Epoch: 003/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 0150/2466 | Cost: 0.0333\n",
            "Epoch: 003/010 | Batch 0200/2466 | Cost: 0.0006\n",
            "Epoch: 003/010 | Batch 0250/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 0300/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 0350/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 0400/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 0450/2466 | Cost: 0.0028\n",
            "Epoch: 003/010 | Batch 0500/2466 | Cost: 0.0007\n",
            "Epoch: 003/010 | Batch 0550/2466 | Cost: 0.0006\n",
            "Epoch: 003/010 | Batch 0600/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 0650/2466 | Cost: 0.0003\n",
            "Epoch: 003/010 | Batch 0700/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 0750/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 0800/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 0850/2466 | Cost: 0.0003\n",
            "Epoch: 003/010 | Batch 0900/2466 | Cost: 0.0010\n",
            "Epoch: 003/010 | Batch 0950/2466 | Cost: 0.0019\n",
            "Epoch: 003/010 | Batch 1000/2466 | Cost: 0.0291\n",
            "Epoch: 003/010 | Batch 1050/2466 | Cost: 0.0002\n",
            "Epoch: 003/010 | Batch 1100/2466 | Cost: 0.0002\n",
            "Epoch: 003/010 | Batch 1150/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 1200/2466 | Cost: 0.0024\n",
            "Epoch: 003/010 | Batch 1250/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 1300/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 1350/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 1400/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 1450/2466 | Cost: 0.0033\n",
            "Epoch: 003/010 | Batch 1500/2466 | Cost: 0.0002\n",
            "Epoch: 003/010 | Batch 1550/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 1600/2466 | Cost: 0.0003\n",
            "Epoch: 003/010 | Batch 1650/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 1700/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 1750/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 1800/2466 | Cost: 0.0017\n",
            "Epoch: 003/010 | Batch 1850/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 1900/2466 | Cost: 0.0038\n",
            "Epoch: 003/010 | Batch 1950/2466 | Cost: 0.0002\n",
            "Epoch: 003/010 | Batch 2000/2466 | Cost: 0.0005\n",
            "Epoch: 003/010 | Batch 2050/2466 | Cost: 0.0016\n",
            "Epoch: 003/010 | Batch 2100/2466 | Cost: 0.0022\n",
            "Epoch: 003/010 | Batch 2150/2466 | Cost: 0.0001\n",
            "Epoch: 003/010 | Batch 2200/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 2250/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 2300/2466 | Cost: 0.0012\n",
            "Epoch: 003/010 | Batch 2350/2466 | Cost: 0.0000\n",
            "Epoch: 003/010 | Batch 2400/2466 | Cost: 0.0007\n",
            "Epoch: 003/010 | Batch 2450/2466 | Cost: 0.0003\n",
            "Epoch: 003/010 | Train: 0.994%   | Val: 0.995%\n",
            "Time elapsed: 8.80 min\n",
            "Epoch: 004/010 | Batch 0000/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0050/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0150/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 0200/2466 | Cost: 0.0015\n",
            "Epoch: 004/010 | Batch 0250/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0300/2466 | Cost: 0.0037\n",
            "Epoch: 004/010 | Batch 0350/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0400/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0450/2466 | Cost: 0.0002\n",
            "Epoch: 004/010 | Batch 0500/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0550/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0600/2466 | Cost: 0.0004\n",
            "Epoch: 004/010 | Batch 0650/2466 | Cost: 0.0007\n",
            "Epoch: 004/010 | Batch 0700/2466 | Cost: 0.0005\n",
            "Epoch: 004/010 | Batch 0750/2466 | Cost: 0.0005\n",
            "Epoch: 004/010 | Batch 0800/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 0850/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 0900/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 0950/2466 | Cost: 0.0011\n",
            "Epoch: 004/010 | Batch 1000/2466 | Cost: 0.0003\n",
            "Epoch: 004/010 | Batch 1050/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1100/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1150/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1200/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 1250/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1300/2466 | Cost: 0.0002\n",
            "Epoch: 004/010 | Batch 1350/2466 | Cost: 0.0021\n",
            "Epoch: 004/010 | Batch 1400/2466 | Cost: 0.0005\n",
            "Epoch: 004/010 | Batch 1450/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1500/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1550/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1600/2466 | Cost: 0.0004\n",
            "Epoch: 004/010 | Batch 1650/2466 | Cost: 0.0017\n",
            "Epoch: 004/010 | Batch 1700/2466 | Cost: 0.0002\n",
            "Epoch: 004/010 | Batch 1750/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1800/2466 | Cost: 0.0017\n",
            "Epoch: 004/010 | Batch 1850/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1900/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 1950/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 2000/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 2050/2466 | Cost: 0.0025\n",
            "Epoch: 004/010 | Batch 2100/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 2150/2466 | Cost: 0.0002\n",
            "Epoch: 004/010 | Batch 2200/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 2250/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 2300/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 2350/2466 | Cost: 0.0001\n",
            "Epoch: 004/010 | Batch 2400/2466 | Cost: 0.0000\n",
            "Epoch: 004/010 | Batch 2450/2466 | Cost: 0.0034\n",
            "Epoch: 004/010 | Train: 0.994%   | Val: 0.996%\n",
            "Time elapsed: 11.78 min\n",
            "Epoch: 005/010 | Batch 0000/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0050/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0150/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0200/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0250/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0300/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0350/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0400/2466 | Cost: 0.0017\n",
            "Epoch: 005/010 | Batch 0450/2466 | Cost: 0.0010\n",
            "Epoch: 005/010 | Batch 0500/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0550/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0600/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0650/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0700/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0750/2466 | Cost: 0.0004\n",
            "Epoch: 005/010 | Batch 0800/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 0850/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0900/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 0950/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1000/2466 | Cost: 0.0004\n",
            "Epoch: 005/010 | Batch 1050/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 1100/2466 | Cost: 0.0006\n",
            "Epoch: 005/010 | Batch 1150/2466 | Cost: 0.0007\n",
            "Epoch: 005/010 | Batch 1200/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 1250/2466 | Cost: 0.0007\n",
            "Epoch: 005/010 | Batch 1300/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1350/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 1400/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1450/2466 | Cost: 0.0009\n",
            "Epoch: 005/010 | Batch 1500/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1550/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1600/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 1650/2466 | Cost: 0.0004\n",
            "Epoch: 005/010 | Batch 1700/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1750/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 1800/2466 | Cost: 0.0038\n",
            "Epoch: 005/010 | Batch 1850/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 1900/2466 | Cost: 0.0181\n",
            "Epoch: 005/010 | Batch 1950/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2000/2466 | Cost: 0.0011\n",
            "Epoch: 005/010 | Batch 2050/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2100/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2150/2466 | Cost: 0.0001\n",
            "Epoch: 005/010 | Batch 2200/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2250/2466 | Cost: 0.0005\n",
            "Epoch: 005/010 | Batch 2300/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2350/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2400/2466 | Cost: 0.0000\n",
            "Epoch: 005/010 | Batch 2450/2466 | Cost: 0.0002\n",
            "Epoch: 005/010 | Train: 0.995%   | Val: 0.997%\n",
            "Time elapsed: 14.90 min\n",
            "Epoch: 006/010 | Batch 0000/2466 | Cost: 0.0003\n",
            "Epoch: 006/010 | Batch 0050/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0150/2466 | Cost: 0.0003\n",
            "Epoch: 006/010 | Batch 0200/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0250/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0300/2466 | Cost: 0.0001\n",
            "Epoch: 006/010 | Batch 0350/2466 | Cost: 0.0005\n",
            "Epoch: 006/010 | Batch 0400/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0450/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0500/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0550/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0600/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0650/2466 | Cost: 0.0029\n",
            "Epoch: 006/010 | Batch 0700/2466 | Cost: 0.0004\n",
            "Epoch: 006/010 | Batch 0750/2466 | Cost: 0.0005\n",
            "Epoch: 006/010 | Batch 0800/2466 | Cost: 0.0005\n",
            "Epoch: 006/010 | Batch 0850/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0900/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 0950/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1000/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1050/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1100/2466 | Cost: 0.0209\n",
            "Epoch: 006/010 | Batch 1150/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1200/2466 | Cost: 0.0001\n",
            "Epoch: 006/010 | Batch 1250/2466 | Cost: 0.0014\n",
            "Epoch: 006/010 | Batch 1300/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1350/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1400/2466 | Cost: 0.0023\n",
            "Epoch: 006/010 | Batch 1450/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1500/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1550/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1600/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1650/2466 | Cost: 0.0024\n",
            "Epoch: 006/010 | Batch 1700/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1750/2466 | Cost: 0.0009\n",
            "Epoch: 006/010 | Batch 1800/2466 | Cost: 0.0002\n",
            "Epoch: 006/010 | Batch 1850/2466 | Cost: 0.0004\n",
            "Epoch: 006/010 | Batch 1900/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 1950/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 2000/2466 | Cost: 0.0242\n",
            "Epoch: 006/010 | Batch 2050/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 2100/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 2150/2466 | Cost: 0.0001\n",
            "Epoch: 006/010 | Batch 2200/2466 | Cost: 0.0003\n",
            "Epoch: 006/010 | Batch 2250/2466 | Cost: 0.0001\n",
            "Epoch: 006/010 | Batch 2300/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 2350/2466 | Cost: 0.0000\n",
            "Epoch: 006/010 | Batch 2400/2466 | Cost: 0.0017\n",
            "Epoch: 006/010 | Batch 2450/2466 | Cost: 0.0002\n",
            "Epoch: 006/010 | Train: 0.996%   | Val: 0.997%\n",
            "Time elapsed: 18.72 min\n",
            "Epoch: 007/010 | Batch 0000/2466 | Cost: 0.0005\n",
            "Epoch: 007/010 | Batch 0050/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0150/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0200/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0250/2466 | Cost: 0.0002\n",
            "Epoch: 007/010 | Batch 0300/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0350/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0400/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0450/2466 | Cost: 0.0012\n",
            "Epoch: 007/010 | Batch 0500/2466 | Cost: 0.0007\n",
            "Epoch: 007/010 | Batch 0550/2466 | Cost: 0.0001\n",
            "Epoch: 007/010 | Batch 0600/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0650/2466 | Cost: 0.0001\n",
            "Epoch: 007/010 | Batch 0700/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0750/2466 | Cost: 0.0005\n",
            "Epoch: 007/010 | Batch 0800/2466 | Cost: 0.0001\n",
            "Epoch: 007/010 | Batch 0850/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0900/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 0950/2466 | Cost: 0.0007\n",
            "Epoch: 007/010 | Batch 1000/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1050/2466 | Cost: 0.0011\n",
            "Epoch: 007/010 | Batch 1100/2466 | Cost: 0.0008\n",
            "Epoch: 007/010 | Batch 1150/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1200/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1250/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1300/2466 | Cost: 0.0001\n",
            "Epoch: 007/010 | Batch 1350/2466 | Cost: 0.0002\n",
            "Epoch: 007/010 | Batch 1400/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1450/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1500/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1550/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1600/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1650/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1700/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1750/2466 | Cost: 0.0004\n",
            "Epoch: 007/010 | Batch 1800/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1850/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 1900/2466 | Cost: 0.0001\n",
            "Epoch: 007/010 | Batch 1950/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 2000/2466 | Cost: 0.0006\n",
            "Epoch: 007/010 | Batch 2050/2466 | Cost: 0.0001\n",
            "Epoch: 007/010 | Batch 2100/2466 | Cost: 0.0010\n",
            "Epoch: 007/010 | Batch 2150/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 2200/2466 | Cost: 0.0097\n",
            "Epoch: 007/010 | Batch 2250/2466 | Cost: 0.0016\n",
            "Epoch: 007/010 | Batch 2300/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Batch 2350/2466 | Cost: 0.0123\n",
            "Epoch: 007/010 | Batch 2400/2466 | Cost: 0.0005\n",
            "Epoch: 007/010 | Batch 2450/2466 | Cost: 0.0000\n",
            "Epoch: 007/010 | Train: 0.995%   | Val: 0.997%\n",
            "Time elapsed: 22.41 min\n",
            "Epoch: 008/010 | Batch 0000/2466 | Cost: 0.0003\n",
            "Epoch: 008/010 | Batch 0050/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0150/2466 | Cost: 0.0011\n",
            "Epoch: 008/010 | Batch 0200/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 0250/2466 | Cost: 0.0012\n",
            "Epoch: 008/010 | Batch 0300/2466 | Cost: 0.0006\n",
            "Epoch: 008/010 | Batch 0350/2466 | Cost: 0.0003\n",
            "Epoch: 008/010 | Batch 0400/2466 | Cost: 0.0004\n",
            "Epoch: 008/010 | Batch 0450/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0500/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 0550/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 0600/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0650/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0700/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0750/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0800/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0850/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 0900/2466 | Cost: 0.0026\n",
            "Epoch: 008/010 | Batch 0950/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1000/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1050/2466 | Cost: 0.0010\n",
            "Epoch: 008/010 | Batch 1100/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1150/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1200/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1250/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1300/2466 | Cost: 0.0004\n",
            "Epoch: 008/010 | Batch 1350/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1400/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1450/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1500/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1550/2466 | Cost: 0.0003\n",
            "Epoch: 008/010 | Batch 1600/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1650/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1700/2466 | Cost: 0.0140\n",
            "Epoch: 008/010 | Batch 1750/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1800/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1850/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 1900/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 1950/2466 | Cost: 0.0004\n",
            "Epoch: 008/010 | Batch 2000/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 2050/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 2100/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 2150/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 2200/2466 | Cost: 0.0009\n",
            "Epoch: 008/010 | Batch 2250/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 2300/2466 | Cost: 0.0001\n",
            "Epoch: 008/010 | Batch 2350/2466 | Cost: 0.0002\n",
            "Epoch: 008/010 | Batch 2400/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Batch 2450/2466 | Cost: 0.0000\n",
            "Epoch: 008/010 | Train: 0.996%   | Val: 0.997%\n",
            "Time elapsed: 26.15 min\n",
            "Epoch: 009/010 | Batch 0000/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0050/2466 | Cost: 0.0010\n",
            "Epoch: 009/010 | Batch 0100/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0150/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0200/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0250/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0300/2466 | Cost: 0.0007\n",
            "Epoch: 009/010 | Batch 0350/2466 | Cost: 0.0001\n",
            "Epoch: 009/010 | Batch 0400/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0450/2466 | Cost: 0.0007\n",
            "Epoch: 009/010 | Batch 0500/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0550/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0600/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0650/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0700/2466 | Cost: 0.0005\n",
            "Epoch: 009/010 | Batch 0750/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 0800/2466 | Cost: 0.0001\n",
            "Epoch: 009/010 | Batch 0850/2466 | Cost: 0.0002\n",
            "Epoch: 009/010 | Batch 0900/2466 | Cost: 0.0005\n",
            "Epoch: 009/010 | Batch 0950/2466 | Cost: 0.0117\n",
            "Epoch: 009/010 | Batch 1000/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1050/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1100/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1150/2466 | Cost: 0.0002\n",
            "Epoch: 009/010 | Batch 1200/2466 | Cost: 0.0057\n",
            "Epoch: 009/010 | Batch 1250/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1300/2466 | Cost: 0.0002\n",
            "Epoch: 009/010 | Batch 1350/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1400/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1450/2466 | Cost: 0.0001\n",
            "Epoch: 009/010 | Batch 1500/2466 | Cost: 0.0001\n",
            "Epoch: 009/010 | Batch 1550/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1600/2466 | Cost: 0.0001\n",
            "Epoch: 009/010 | Batch 1650/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1700/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1750/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1800/2466 | Cost: 0.0003\n",
            "Epoch: 009/010 | Batch 1850/2466 | Cost: 0.0024\n",
            "Epoch: 009/010 | Batch 1900/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 1950/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2000/2466 | Cost: 0.0006\n",
            "Epoch: 009/010 | Batch 2050/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2100/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2150/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2200/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2250/2466 | Cost: 0.0002\n",
            "Epoch: 009/010 | Batch 2300/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2350/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Batch 2400/2466 | Cost: 0.0001\n",
            "Epoch: 009/010 | Batch 2450/2466 | Cost: 0.0000\n",
            "Epoch: 009/010 | Train: 0.996%   | Val: 0.997%\n",
            "Time elapsed: 29.78 min\n",
            "Epoch: 010/010 | Batch 0000/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0050/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0100/2466 | Cost: 0.0008\n",
            "Epoch: 010/010 | Batch 0150/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0200/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0250/2466 | Cost: 0.0012\n",
            "Epoch: 010/010 | Batch 0300/2466 | Cost: 0.0005\n",
            "Epoch: 010/010 | Batch 0350/2466 | Cost: 0.0002\n",
            "Epoch: 010/010 | Batch 0400/2466 | Cost: 0.0001\n",
            "Epoch: 010/010 | Batch 0450/2466 | Cost: 0.0001\n",
            "Epoch: 010/010 | Batch 0500/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0550/2466 | Cost: 0.0002\n",
            "Epoch: 010/010 | Batch 0600/2466 | Cost: 0.0003\n",
            "Epoch: 010/010 | Batch 0650/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0700/2466 | Cost: 0.0001\n",
            "Epoch: 010/010 | Batch 0750/2466 | Cost: 0.0011\n",
            "Epoch: 010/010 | Batch 0800/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0850/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0900/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 0950/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1000/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1050/2466 | Cost: 0.0017\n",
            "Epoch: 010/010 | Batch 1100/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1150/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1200/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1250/2466 | Cost: 0.0007\n",
            "Epoch: 010/010 | Batch 1300/2466 | Cost: 0.0002\n",
            "Epoch: 010/010 | Batch 1350/2466 | Cost: 0.0003\n",
            "Epoch: 010/010 | Batch 1400/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1450/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1500/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1550/2466 | Cost: 0.0001\n",
            "Epoch: 010/010 | Batch 1600/2466 | Cost: 0.0001\n",
            "Epoch: 010/010 | Batch 1650/2466 | Cost: 0.0004\n",
            "Epoch: 010/010 | Batch 1700/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1750/2466 | Cost: 0.0011\n",
            "Epoch: 010/010 | Batch 1800/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1850/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 1900/2466 | Cost: 0.0001\n",
            "Epoch: 010/010 | Batch 1950/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2000/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2050/2466 | Cost: 0.0011\n",
            "Epoch: 010/010 | Batch 2100/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2150/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2200/2466 | Cost: 0.0002\n",
            "Epoch: 010/010 | Batch 2250/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2300/2466 | Cost: 0.0017\n",
            "Epoch: 010/010 | Batch 2350/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2400/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Batch 2450/2466 | Cost: 0.0000\n",
            "Epoch: 010/010 | Train: 0.997%   | Val: 0.998%\n",
            "Time elapsed: 33.24 min\n",
            "Total Training Time: 33.24 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU3oYIU_S3co",
        "outputId": "b3fd7746-e5b5-45f5-d38d-5f0c256a44f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "EGRqtOSy-yU5",
        "outputId": "eea17702-3c65-41c1-f230-82041fe48acf"
      },
      "source": [
        "# plot cost functions\n",
        "minibatch_cost_cpu = [i.cpu().detach().numpy() for i in minibatch_cost]\n",
        "\n",
        "plt.plot(range(len(minibatch_cost_cpu)), minibatch_cost_cpu)\n",
        "plt.ylabel('Cost Function Label')\n",
        "plt.xlabel('Minibatch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(epoch_train_performance)), epoch_train_performance, label=\"train f1 scores\")\n",
        "plt.plot(range(len(epoch_val_performance)), epoch_val_performance, label=\"val f1 scores\")\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obJPMecX-yU6"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03nz_tXO-yU7",
        "outputId": "1e94eb79-20cf-404e-e00d-2da57fd87c04"
      },
      "source": [
        "# Evaluate metrics on the test set\n",
        "y_hats = []\n",
        "y_acts = []\n",
        "counter = 0\n",
        "for i, (inputs, targets) in enumerate(test_loader):\n",
        "    yhat = model(inputs)[-1].cpu().detach().numpy().round()\n",
        "    yhat = np.argmax(yhat, axis=1)\n",
        "    y_hats.append(yhat)\n",
        "    y_acts.append(list(targets.cpu().detach().numpy()))\n",
        "    counter += 1\n",
        "\n",
        "y_hats = [item for sublist in y_hats for item in sublist]\n",
        "y_acts = [item for sublist in y_acts for item in sublist]\n",
        "\n",
        "print(\"TEST SET METRICS:\")\n",
        "f1 = f1_score(y_acts, y_hats)\n",
        "print(\"f1 score : \", f1)\n",
        "precision = precision_score(y_acts, y_hats)\n",
        "print(\"precision\", precision)\n",
        "recall = recall_score(y_acts, y_hats)\n",
        "print(\"recall\", recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SET METRICS:\n",
            "f1 score :  0.9979787771601819\n",
            "precision 1.0\n",
            "recall 0.9959657085224407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3_a-OxwsJwp",
        "outputId": "dec37d49-5897-4532-a417-fcc20e720eaa"
      },
      "source": [
        "test_ys = pd.DataFrame(list(zip(y_acts, y_hats)), columns=[\"y_true\", \"y_pred\"])\n",
        "\n",
        "print(\"TEST SET:\\n\")\n",
        "print(\"anomalous:\\n\")\n",
        "test_anomalous = test_ys[test_ys[\"y_true\"]==1]\n",
        "print(\"number of anomalies in the test set:\", len(test_anomalous))\n",
        "correct_anomalous = test_anomalous[test_anomalous[\"y_true\"] == test_anomalous[\"y_pred\"]]\n",
        "print(\"number of anomalies correctly identified\", len(correct_anomalous))\n",
        "incorrect_anomalous = test_anomalous[test_anomalous[\"y_true\"] != test_anomalous[\"y_pred\"]]\n",
        "print(\"number of anomalies incorrectly identified\", len(incorrect_anomalous))\n",
        "\n",
        "print(\"\\nnormal:\\n\")\n",
        "test_normals = test_ys[test_ys[\"y_true\"]==0]\n",
        "print(\"number of normals in the test set:\", len(test_normals))\n",
        "correct_normal = test_normals[test_normals[\"y_true\"] == test_normals[\"y_pred\"]]\n",
        "print(\"number of normals correctly identified\", len(correct_normal))\n",
        "incorrect_normal = test_normals[test_normals[\"y_true\"] != test_normals[\"y_pred\"]]\n",
        "print(\"number of normals incorrectly identified\", len(incorrect_normal))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SET:\n",
            "\n",
            "anomalous:\n",
            "\n",
            "number of anomalies in the test set: 1983\n",
            "number of anomalies correctly identified 1975\n",
            "number of anomalies incorrectly identified 8\n",
            "\n",
            "normal:\n",
            "\n",
            "number of normals in the test set: 118554\n",
            "number of normals correctly identified 118554\n",
            "number of normals incorrectly identified 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW4Z3-S5pPsR",
        "outputId": "5b6bae6a-c483-4e74-e0e1-b57417defd1f"
      },
      "source": [
        "# Evaluate metrics on train set\n",
        "y_hats = []\n",
        "y_acts = []\n",
        "counter = 0\n",
        "for i, (inputs, targets) in enumerate(train_loader):\n",
        "    yhat = model(inputs)[-1].cpu().detach().numpy().round()\n",
        "    yhat = np.argmax(yhat, axis=1)\n",
        "    y_hats.append(yhat)\n",
        "    y_acts.append(list(targets.cpu().detach().numpy()))\n",
        "    counter += 1\n",
        "\n",
        "y_hats = [item for sublist in y_hats for item in sublist]\n",
        "y_acts = [item for sublist in y_acts for item in sublist]\n",
        "\n",
        "print(\"TRAIN SET METRICS:\")\n",
        "f1 = f1_score(y_acts, y_hats)\n",
        "print(\"f1 score : \", f1)\n",
        "precision = precision_score(y_acts, y_hats)\n",
        "print(\"precision\", precision)\n",
        "recall = recall_score(y_acts, y_hats)\n",
        "print(\"recall\", recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN SET METRICS:\n",
            "f1 score :  0.9965922384415848\n",
            "precision 0.9960349735664904\n",
            "recall 0.9971501272264631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqZLZHRRpv-3",
        "outputId": "5e14d124-55d5-4a16-d8bc-506604e9406a"
      },
      "source": [
        "train_ys = pd.DataFrame(list(zip(y_acts, y_hats)), columns=[\"y_true\", \"y_pred\"])\n",
        "print(\"TRAIN SET:\\n\")\n",
        "print(\"anomalous:\\n\")\n",
        "train_anomalous = train_ys[train_ys[\"y_true\"]==1]\n",
        "print(\"number of anomalies in the train set:\", len(train_anomalous))\n",
        "correct_anomalous = train_anomalous[train_anomalous[\"y_true\"] == train_anomalous[\"y_pred\"]]\n",
        "print(\"number of anomalies correctly identified\", len(correct_anomalous))\n",
        "incorrect_anomalous = train_anomalous[train_anomalous[\"y_true\"] != train_anomalous[\"y_pred\"]]\n",
        "print(\"number of anomalies incorrectly identified\", len(incorrect_anomalous))\n",
        "\n",
        "print(\"\\nnormal:\\n\")\n",
        "train_normals = train_ys[train_ys[\"y_true\"]==0]\n",
        "print(\"number of normals in the train set:\", len(train_normals))\n",
        "correct_normal = train_normals[train_normals[\"y_true\"] == train_normals[\"y_pred\"]]\n",
        "print(\"number of normals correctly identified\", len(correct_normal))\n",
        "incorrect_normal = train_normals[train_normals[\"y_true\"] != train_normals[\"y_pred\"]]\n",
        "print(\"number of normals incorrectly identified\", len(incorrect_normal))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN SET:\n",
            "\n",
            "anomalous:\n",
            "\n",
            "number of anomalies in the train set: 9825\n",
            "number of anomalies correctly identified 9797\n",
            "number of anomalies incorrectly identified 28\n",
            "\n",
            "normal:\n",
            "\n",
            "number of normals in the train set: 305777\n",
            "number of normals correctly identified 305738\n",
            "number of normals incorrectly identified 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN9sqHAiu3LG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}